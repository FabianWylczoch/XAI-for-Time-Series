
@article{dau_ucr_2019,
	title = {The {UCR} time series archive},
	volume = {6},
	issn = {2329-9274},
	url = {https://ieeexplore.ieee.org/document/8894743/?arnumber=8894743},
	doi = {10.1109/JAS.2019.1911747},
	abstract = {The UCR time series archive–introduced in 2002, has become an important resource in the time series data mining community, with at least one thousand published papers making use of at least one data set from the archive. The original incarnation of the archive had sixteen data sets but since that time, it has gone through periodic expansions. The last expansion took place in the summer of 2015 when the archive grew from 45 to 85 data sets. This paper introduces and will focus on the new data expansion from 85 to 128 data sets. Beyond expanding this valuable resource, this paper offers pragmatic advice to anyone who may wish to evaluate a new algorithm on the archive. Finally, this paper makes a novel and yet actionable claim: of the hundreds of papers that show an improvement over the standard baseline ( 1-nearest neighbor classification ), a fraction might be mis-attributing the reasons for their improvement. Moreover, the improvements claimed by these papers might have been achievable with a much simpler modification, requiring just a few lines of code.},
	number = {6},
	urldate = {2025-01-28},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
	month = nov,
	year = {2019},
	note = {Conference Name: IEEE/CAA Journal of Automatica Sinica},
	keywords = {Cameras, Data mining, Error analysis, Euclidean distance, Microsoft Windows, Time series analysis, Training},
	pages = {1293--1305},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/3XAC98TL/Dau et al. - 2019 - The UCR time series archive.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/CIPUJ7R9/8894743.html:text/html},
}

@inproceedings{ye_time_2009,
	address = {Paris France},
	title = {Time series shapelets: a new primitive for data mining},
	isbn = {978-1-60558-495-9},
	shorttitle = {Time series shapelets},
	url = {https://dl.acm.org/doi/10.1145/1557019.1557122},
	doi = {10.1145/1557019.1557122},
	abstract = {Classification of time series has been attracting great interest over the past decade. Recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data.},
	language = {en},
	urldate = {2025-01-28},
	booktitle = {Proceedings of the 15th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Ye, Lexiang and Keogh, Eamonn},
	month = jun,
	year = {2009},
	pages = {947--956},
	file = {Ye und Keogh - 2009 - Time series shapelets a new primitive for data mi.pdf:/Users/fabian/Zotero/storage/5ARGJ64H/Ye und Keogh - 2009 - Time series shapelets a new primitive for data mi.pdf:application/pdf},
}

@article{keogh_lb_keogh_nodate,
	title = {{LB}\_Keogh {Supports} {Exact} {Indexing} of {Shapes} under {Rotation} {Invariance} with {Arbitrary} {Representations} and {Distance} {Measures}},
	abstract = {The matching of two-dimensional shapes is an important problem with applications in domains as diverse as biometrics, industry, medicine and anthropology. The distance measure used must be invariant to many distortions, including scale, offset, noise, partial occlusion, etc. Most of these distortions are relatively easy to handle, either in the representation of the data or in the similarity measure used. However rotation invariance seems to be uniquely difficult. Current approaches typically try to achieve rotation invariance in the representation of the data, at the expense of discrimination ability, or in the distance measure, at the expense of efficiency. In this work we show that we can take the slow but accurate approaches and dramatically speed them up. On real world problems our technique can take current approaches and make them four orders of magnitude faster, without false dismissals. Moreover, our technique can be used with any of the dozens of existing shape representations and with all the most popular distance measures including Euclidean distance, Dynamic Time Warping and Longest Common Subsequence.},
	language = {en},
	author = {Keogh, Eamonn and Wei, Li and Xi, Xiaopeng and Lee, Sang-Hee and Vlachos, Michail},
	file = {Keogh et al. - LB_Keogh Supports Exact Indexing of Shapes under R.pdf:/Users/fabian/Zotero/storage/YPJTQLAJ/Keogh et al. - LB_Keogh Supports Exact Indexing of Shapes under R.pdf:application/pdf},
}

@inproceedings{hollig_xtsc-bench_2023,
	title = {{XTSC}-{Bench}: {Quantitative} {Benchmarking} for {Explainers} on {Time} {Series} {Classification}},
	shorttitle = {{XTSC}-{Bench}},
	url = {https://ieeexplore.ieee.org/document/10459958/?arnumber=10459958},
	doi = {10.1109/ICMLA58977.2023.00168},
	abstract = {Despite the growing body of work on explainable machine learning in time series classification (TSC), it remains unclear how to evaluate different explainability methods. Resorting to qualitative assessment and user studies to evaluate explainers for TSC is difficult since humans have difficulties understanding the underlying information contained in time series data. Therefore, a systematic review and quantitative comparison of explanation methods to confirm their correctness becomes crucial. While steps to standardized evaluations were taken for tabular, image, and textual data, benchmarking explainability methods on time series is challenging due to a) traditional metrics not being directly applicable, b) implementation and adaption of traditional metrics for time series in the literature vary, and c) varying baseline implementations. This paper proposes XTSC-Bench, a benchmarking tool providing standardized datasets, models, and metrics for evaluating explanation methods on TSC. We analyze 3 perturbation-, 6 gradient- and 2 example-based explanation methods to TSC showing that improvements in the explainers' robustness and reliability are necessary, especially for multivariate data.},
	urldate = {2025-01-28},
	booktitle = {2023 {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	author = {Höllig, Jacqueline and Thoma, Steffen and Grimm, Florian},
	month = dec,
	year = {2023},
	note = {ISSN: 1946-0759},
	keywords = {Benchmark testing, Explainable AI, Feature extraction, Machine learning, Measurement, Reviews, Systematics, Time series analysis, Time Series Classification, XAI Metrics},
	pages = {1126--1131},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/5WLFZLPA/Höllig et al. - 2023 - XTSC-Bench Quantitative Benchmarking for Explaine.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/XYXDB494/10459958.html:text/html},
}

@inproceedings{grabocka_learning_2014,
	address = {New York New York USA},
	title = {Learning time-series shapelets},
	isbn = {978-1-4503-2956-9},
	url = {https://dl.acm.org/doi/10.1145/2623330.2623613},
	doi = {10.1145/2623330.2623613},
	abstract = {Shapelets are discriminative sub-sequences of time series that best predict the target variable. For this reason, shapelet discovery has recently attracted considerable interest within the time-series research community. Currently shapelets are found by evaluating the prediction qualities of numerous candidates extracted from the series segments. In contrast to the state-of-the-art, this paper proposes a novel perspective in terms of learning shapelets. A new mathematical formalization of the task via a classiﬁcation objective function is proposed and a tailored stochastic gradient learning algorithm is applied. The proposed method enables learning nearto-optimal shapelets directly without the need to try out lots of candidates. Furthermore, our method can learn true top-K shapelets by capturing their interaction. Extensive experimentation demonstrates statistically signiﬁcant improvement in terms of wins and ranks against 13 baselines over 28 time-series datasets.},
	language = {en},
	urldate = {2025-01-28},
	booktitle = {Proceedings of the 20th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Grabocka, Josif and Schilling, Nicolas and Wistuba, Martin and Schmidt-Thieme, Lars},
	month = aug,
	year = {2014},
	pages = {392--401},
	file = {Grabocka et al. - 2014 - Learning time-series shapelets.pdf:/Users/fabian/Zotero/storage/INUVHW6J/Grabocka et al. - 2014 - Learning time-series shapelets.pdf:application/pdf},
}

@article{briandet_discrimination_1996,
	title = {Discrimination of {Arabica} and {Robusta} in {Instant} {Coffee} by {Fourier} {Transform} {Infrared} {Spectroscopy} and {Chemometrics}},
	volume = {44},
	issn = {0021-8561},
	url = {https://doi.org/10.1021/jf950305a},
	doi = {10.1021/jf950305a},
	abstract = {Two species of coffee bean have acquired worldwide economic importance:  these are, Coffea Arabica and Coffea Canephora variant Robusta. Arabica beans are valued most highly by the trade, as they are considered to have a finer flavor than Robusta. In this work, Fourier transform infrared spectroscopy is explored as a rapid alternative to wet chemical methods for authentication and quantification of coffee products. Principal component analysis (PCA) is applied to spectra of freeze-dried instant coffees, acquired by DRIFT (diffuse reflection infrared Fourier transform) and ATR (attenuated total reflection) sampling techniques, and reveals clustering according to coffee species. Linear discriminant analysis of the principal component scores yields 100\% correct classifications for both training and test samples. The chemical origin of the discrimination is explored through interpretation of the PCA loadings. Partial least squares regression is applied to spectra of Arabica and Robusta blends to determine the relative content of each species. Internal cross-validation gives a correlation coefficient of 0.99 and a standard error of prediction of 1.20\% (w/w), illustrating the potential of the method for industrial off-line quality control analysis. Keywords: Coffee; discrimination; infrared; spectroscopy},
	number = {1},
	urldate = {2025-01-28},
	journal = {Journal of Agricultural and Food Chemistry},
	author = {Briandet, Romain and Kemsley, E. Katherine and Wilson, Reginald H.},
	month = jan,
	year = {1996},
	note = {Publisher: American Chemical Society},
	pages = {170--174},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/2EPVV8US/Briandet et al. - 1996 - Discrimination of Arabica and Robusta in Instant C.pdf:application/pdf},
}

@misc{rojat_explainable_2021,
	title = {Explainable {Artificial} {Intelligence} ({XAI}) on {TimeSeries} {Data}: {A} {Survey}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI}) on {TimeSeries} {Data}},
	url = {http://arxiv.org/abs/2104.00950},
	doi = {10.48550/arXiv.2104.00950},
	abstract = {Most of state of the art methods applied on time series consist of deep learning methods that are too complex to be interpreted. This lack of interpretability is a major drawback, as several applications in the real world are critical tasks, such as the medical ﬁeld or the autonomous driving ﬁeld. The explainability of models applied on time series has not gather much attention compared to the computer vision or the natural language processing ﬁelds. In this paper, we present an overview of existing explainable AI (XAI) methods applied on time series and illustrate the type of explanations they produce. We also provide a reﬂection on the impact of these explanation methods to provide conﬁdence and trust in the AI systems.},
	language = {en},
	urldate = {2025-01-28},
	publisher = {arXiv},
	author = {Rojat, Thomas and Puget, Raphaël and Filliat, David and Ser, Javier Del and Gelin, Rodolphe and Díaz-Rodríguez, Natalia},
	month = apr,
	year = {2021},
	note = {arXiv:2104.00950 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Rojat et al. - 2021 - Explainable Artificial Intelligence (XAI) on TimeS.pdf:/Users/fabian/Zotero/storage/6KK4ELPX/Rojat et al. - 2021 - Explainable Artificial Intelligence (XAI) on TimeS.pdf:application/pdf},
}

@inproceedings{schlegel_towards_2019,
	title = {Towards {A} {Rigorous} {Evaluation} {Of} {XAI} {Methods} {On} {Time} {Series}},
	url = {https://ieeexplore.ieee.org/document/9022428/?arnumber=9022428},
	doi = {10.1109/ICCVW.2019.00516},
	abstract = {Explainable Artificial Intelligence (XAI) methods are typically deployed to explain and debug black-box machine learning models. However, most proposed XAI methods are black-boxes themselves and designed for images. Thus, they rely on visual interpretability to evaluate and prove explanations. In this work, we apply XAI methods previously used in the image and text-domain on time series. We present a methodology to test and evaluate various XAI methods on time series by introducing new verification techniques to incorporate the temporal dimension. We further conduct preliminary experiments to assess the quality of selected XAI method explanations with various verification methods on a range of datasets and inspecting quality metrics on it. We demonstrate that in our initial experiments, SHAP works robust for all models, but others like DeepLIFT, LRP, and Saliency Maps work better with specific architectures.},
	urldate = {2025-01-28},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	author = {Schlegel, Udo and Arnout, Hiba and El-Assady, Mennatallah and Oelke, Daniela and Keim, Daniel A.},
	month = oct,
	year = {2019},
	note = {ISSN: 2473-9944},
	keywords = {Data models, explainable-ai, explainable-ai-evaluation, Heating systems, Machine learning, Perturbation methods, Predictive models, Task analysis, Time series analysis, Time-Series},
	pages = {4197--4201},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/3KKCS5QN/Schlegel et al. - 2019 - Towards A Rigorous Evaluation Of XAI Methods On Ti.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/DQNKKRFY/9022428.html:text/html},
}

@inproceedings{wang_time_2017,
	title = {Time series classification from scratch with deep neural networks: {A} strong baseline},
	shorttitle = {Time series classification from scratch with deep neural networks},
	url = {https://ieeexplore.ieee.org/document/7966039/?arnumber=7966039},
	doi = {10.1109/IJCNN.2017.7966039},
	abstract = {We propose a simple but strong baseline for time series classification from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The proposed Fully Convolutional Network (FCN) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive. The global average pooling in our convolutional model enables the exploitation of the Class Activation Map (CAM) to find out the contributing region in the raw data for the specific labels. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classification semantics.},
	urldate = {2025-01-28},
	booktitle = {2017 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Wang, Zhiguang and Yan, Weizhong and Oates, Tim},
	month = may,
	year = {2017},
	note = {ISSN: 2161-4407},
	keywords = {Benchmark testing, Convolution, Feature extraction, Neural networks, Standards, Time series analysis, Training},
	pages = {1578--1585},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/52SCWQ4K/Wang et al. - 2017 - Time series classification from scratch with deep .pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/VJESCBL2/7966039.html:text/html},
}

@article{li_efficient_2022,
	title = {Efficient {Shapelet} {Discovery} for {Time} {Series} {Classification}},
	volume = {34},
	issn = {1558-2191},
	url = {https://ieeexplore.ieee.org/document/9096567/?arnumber=9096567},
	doi = {10.1109/TKDE.2020.2995870},
	abstract = {Time-series shapelets are discriminative subsequences, recently found effective for time series classification (tsc). It is evident that the quality of shapelets is crucial to the accuracy of tsc. However, major research has focused on building accurate models from some shapelet candidates. To determine such candidates, existing studies are surprisingly simple, e.g., enumerating subsequences of some fixed lengths, or randomly selecting some subsequences as shapelet candidates. The major bulk of computation is then on building the model from the candidates. In this paper, we propose a novel efficient shapelet discovery method, called bspcover, to discover a set of high-quality shapelet candidates for model building. Specifically, bspcover generates abundant candidates via Symbolic Aggregate approXimation with sliding window, then prunes identical and highly similar candidates via Bloom filters, and similarity matching, respectively. We next propose a pp-Cover algorithm to efficiently determine discriminative shapelet candidates that maximally represent each time-series class. Finally, any existing shapelet learning method can be adopted to build a classification model. We have conducted extensive experiments with well-known time-series datasets and representative state-of-the-art methods. Results show that bspcover speeds up the state-of-the-art methods by more than 70 times, and the accuracy is often comparable to or higher than existing works.},
	number = {3},
	urldate = {2025-01-28},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Li, Guozhong and Choi, Byron and Xu, Jianliang and Bhowmick, Sourav S and Chun, Kwok-Pan and Wong, Grace Lai-Hung},
	month = mar,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {accuracy, Aggregates, Computational modeling, efficiency, shapelet discovery, Time complexity, Time series analysis, Time series classification, Windows},
	pages = {1149--1163},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/8UWVABTT/Li et al. - 2022 - Efficient Shapelet Discovery for Time Series Class.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/PM6SHQ5L/9096567.html:text/html},
}

@inproceedings{lines_shapelet_2012,
	address = {Beijing China},
	title = {A shapelet transform for time series classification},
	isbn = {978-1-4503-1462-6},
	url = {https://dl.acm.org/doi/10.1145/2339530.2339579},
	doi = {10.1145/2339530.2339579},
	abstract = {The problem of time series classiﬁcation (TSC), where we consider any real-valued ordered data a time series, presents a speciﬁc machine learning challenge as the ordering of variables is often crucial in ﬁnding the best discriminating features. One of the most promising recent approaches is to ﬁnd shapelets within a data set. A shapelet is a time series subsequence that is identiﬁed as being representative of class membership. The original research in this ﬁeld embedded the procedure of ﬁnding shapelets within a decision tree. We propose disconnecting the process of ﬁnding shapelets from the classiﬁcation algorithm by proposing a shapelet transformation. We describe a means of extracting the k best shapelets from a data set in a single pass, and then use these shapelets to transform data by calculating the distances from a series to each shapelet. We demonstrate that transformation into this new data space can improve classiﬁcation accuracy, whilst retaining the explanatory power provided by shapelets.},
	language = {en},
	urldate = {2025-01-28},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Lines, Jason and Davis, Luke M. and Hills, Jon and Bagnall, Anthony},
	month = aug,
	year = {2012},
	pages = {289--297},
	file = {Lines et al. - 2012 - A shapelet transform for time series classificatio.pdf:/Users/fabian/Zotero/storage/TUDM6TLQ/Lines et al. - 2012 - A shapelet transform for time series classificatio.pdf:application/pdf},
}

@article{beggel_time_2019,
	title = {Time series anomaly detection based on shapelet learning},
	volume = {34},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-018-0824-9},
	doi = {10.1007/s00180-018-0824-9},
	abstract = {We consider the problem of learning to detect anomalous time series from an unlabeled data set, possibly contaminated with anomalies in the training data. This scenario is important for applications in medicine, economics, or industrial quality control, in which labeling is difficult and requires expensive expert knowledge, and anomalous data is difficult to obtain. This article presents a novel method for unsupervised anomaly detection based on the shapelet transformation for time series. Our approach learns representative features that describe the shape of time series stemming from the normal class, and simultaneously learns to accurately detect anomalous time series. An objective function is proposed that encourages learning of a feature representation in which the normal time series lie within a compact hypersphere of the feature space, whereas anomalous observations will lie outside of a decision boundary. This objective is optimized by a block-coordinate descent procedure. Our method can efficiently detect anomalous time series in unseen test data without retraining the model by reusing the learned feature representation. We demonstrate on multiple benchmark data sets that our approach reliably detects anomalous time series, and is more robust than competing methods when the training instances contain anomalous time series.},
	number = {3},
	journal = {Computational Statistics},
	author = {Beggel, Laura and Kausler, Bernhard X. and Schiegg, Martin and Pfeiffer, Michael and Bischl, Bernd},
	month = sep,
	year = {2019},
	pages = {945--976},
}

@misc{selvaraju_grad-cam_2017,
	title = {Grad-{CAM}: {Why} did you say that?},
	shorttitle = {Grad-{CAM}},
	url = {http://arxiv.org/abs/1611.07450},
	doi = {10.48550/arXiv.1611.07450},
	abstract = {We propose a technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing input regions that are ‘important’ for predictions – producing visual explanations. Our approach, called Gradient-weighted Class Activation Mapping (Grad-CAM), uses class-speciﬁc gradient information to localize important regions. These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided GradCAM. These methods help better understand CNN-based models, including image captioning and visual question answering (VQA) models. We evaluate our visual explanations by measuring their ability to discriminate between classes, to inspire trust in humans, and their correlation with occlusion maps. Grad-CAM provides a new way to understand CNN-based models.},
	language = {en},
	urldate = {2025-01-28},
	publisher = {arXiv},
	author = {Selvaraju, Ramprasaath R. and Das, Abhishek and Vedantam, Ramakrishna and Cogswell, Michael and Parikh, Devi and Batra, Dhruv},
	month = jan,
	year = {2017},
	note = {arXiv:1611.07450 [stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems. This is an extended abstract version of arXiv:1610.02391 (CVPR format)},
	file = {Selvaraju et al. - 2017 - Grad-CAM Why did you say that.pdf:/Users/fabian/Zotero/storage/P9WUYPXH/Selvaraju et al. - 2017 - Grad-CAM Why did you say that.pdf:application/pdf},
}

@article{zhao_convolutional_2017,
	title = {Convolutional neural networks for time series classification},
	volume = {28},
	issn = {1004-4132},
	url = {https://ieeexplore.ieee.org/document/7870510/?arnumber=7870510},
	doi = {10.21629/JSEE.2017.01.18},
	abstract = {Time series classification is an important task in time series data mining, and has attracted great interests and tremendous efforts during last decades. However, it remains a challenging problem due to the nature of time series data: high dimensionality, large in data size and updating continuously. The deep learning techniques are explored to improve the performance of traditional feature-based approaches. Specifically, a novel convolutional neural network (CNN) framework is proposed for time series classification. Different from other feature-based classification approaches, CNN can discover and extract the suitable internal structure to generate deep features of the input time series automatically by using convolution and pooling operations. Two groups of experiments are conducted on simulated data sets and eight groups of experiments are conducted on real-world data sets from different application domains. The final experimental results show that the proposed method outperforms state-of-the-art methods for time series classification in terms of the classification accuracy and noise tolerance.},
	number = {1},
	urldate = {2025-01-28},
	journal = {Journal of Systems Engineering and Electronics},
	author = {Zhao, Bendong and Lu, Huanzhang and Chen, Shangfeng and Liu, Junliang and Wu, Dongya},
	month = feb,
	year = {2017},
	note = {Conference Name: Journal of Systems Engineering and Electronics},
	keywords = {classification, Convolution, convolutional neural network (CNN), data mining, Data mining, Hidden Markov models, multivariate time series, Neural networks, Neurons, time series, Time series analysis, Training},
	pages = {162--169},
	file = {Full Text PDF:/Users/fabian/Zotero/storage/8ET8S562/Zhao et al. - 2017 - Convolutional neural networks for time series clas.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/fabian/Zotero/storage/WPRE88S6/7870510.html:text/html},
}

@inproceedings{ribeiro_why_2016,
	address = {San Francisco California USA},
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
	doi = {10.1145/2939672.2939778},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classiﬁer in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the ﬂexibility of these methods by explaining diﬀerent models for text (e.g. random forests) and image classiﬁcation (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classiﬁer, and identifying why a classiﬁer should not be trusted.},
	language = {en},
	urldate = {2025-01-28},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	pages = {1135--1144},
	file = {Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:/Users/fabian/Zotero/storage/MBVB5TFJ/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf},
}

@article{yoohyeon-joong_deep_2015,
	title = {Deep {Convolution} {Neural} {Networks} in {Computer} {Vision}: a {Review}},
	volume = {4},
	number = {1},
	journal = {IEIE Transactions on Smart Processing and Computing},
	author = {{YooHyeon-Joong}},
	month = feb,
	year = {2015},
	note = {Publisher: 대한전자공학회},
	pages = {35--43},
}

@article{ozbay_new_2010,
	title = {A new method for classification of {ECG} arrhythmias using neural network with adaptive activation function},
	volume = {20},
	issn = {1051-2004},
	url = {https://www.sciencedirect.com/science/article/pii/S1051200409001948},
	doi = {https://doi.org/10.1016/j.dsp.2009.10.016},
	abstract = {In this study, new neural network models with adaptive activation function (NNAAF) were implemented to classify ECG arrhythmias. Our NNAAF models included three types named as NNAAF-1, NNAAF-2 and NNAAf-3. Activation functions with adjustable free parameters were used in hidden neurons of these models to improve classical MLP network. In addition, these three NNAAF models were compared with the MLP model implemented in similar conditions. Ten different types of ECG arrhythmias were selected from MIT–BIH ECG Arrhythmias Database to train NNAAFs and MLP models. Moreover, all models tested by the ECG signals of 92 patients (40 males and 52 females, average age is 39.75±19.06). The average accuracy rate of all models in the training processing was found as 99.92\%. The average accuracy rate of the all models in the test phases was obtained as 98.19.},
	number = {4},
	journal = {Digital Signal Processing},
	author = {Özbay, Yüksel and Tezel, Gülay},
	year = {2010},
	keywords = {Adaptive activation function, Adaptive neural network, Arrhythmia, Classification, ECG, MLP},
	pages = {1040--1049},
}
